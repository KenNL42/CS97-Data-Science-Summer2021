{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Day9_NN_training_regularization.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyON69GWn2SWo45Iz9RJ+rSq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"EFcHyyvkKWrY"},"source":["#NN: Design, Training, Regularization (Day 9)\n","\n","##Recap\n","\n","\n","<img src=\"https://www.researchgate.net/publication/299474560/figure/fig6/AS:349583008911366@1460358492284/An-example-of-a-deep-neural-network-with-two-hidden-layers-The-first-layer-is-the-input.png\" alt=\"nn\" width=\"400\"/>\n","\n","In neural network (NN), we have three types out layer: input, hidden, output. NN can be used for both classification and regression. However, we need to optimize NN’s components to make it works well with its input type and objective.\n","![table](https://drive.google.com/uc?export=view&id=1J0_K8BJ669aoPD_RRUGskUNoxfyf_DTA)"]},{"cell_type":"markdown","metadata":{"id":"qx7-tlcIVphK"},"source":["##Regularization\n","Regularization happens in learning period, which is intended to reduce its generalization (test) error but not training error. These are different techniques to make the NN more robust:\n","-\tNorm Penalties\n","-\tEarly Stopping\n","-\tData Augmentation\n","-\tDropout\n","\n","##Norm Penalties\n","![nn_penalty](https://miro.medium.com/proxy/0*SY_r-Ltc9mB6pNBK)\n","\n","Key idea: we regularize each weight in the network, so the model becomes less overfitted and achieve higher testing score.\n","\n","---\n","\n","\n","##Early Stopping\n","\n","<img src=\"https://miro.medium.com/max/973/1*nhmPdWSGh3ziatQKOmVq0Q.png\" alt=\"early\" width=\"400\"/>\n","\n","Key idea: terminate while validation/test data performance is better.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=12faTvQffHodPJrtrYSKxivXxR2CXILIK\" alt=\"stop\" width=\"400\"/>\n","\n","\n","---\n","\n","##Data augmentation\n","Note: there will be a mini lab to show how NN can be susceptible to noisy data.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1mzf40FKIt2LKWLpCmqlrvdsJT-fukQqF\" alt=\"panda\" width=\"600\"/>\n","\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1RM6Eua080h5KVuKtqKy0Op9SlR6STJHm\" alt=\"result\" width=\"400\"/>\n","\n","\n","Key idea: training with noisy and transformed data (which is a process called adversarial training) makes the neural network more robust (this is under adversarial defense/attack research field)\n","\n","Source: Cihang Xie, et al. “Adversarial Examples Improve Image Recognition”, 2019; [http://arxiv.org/abs/1911.09665 arXiv:1911.09665].\n","\n","---\n","\n","\n","##Dropout\n","\n","![dropout](https://drive.google.com/uc?export=view&id=10U_pG_BQkrqaHBJ7rpWLHzeoXKU9wCSl)\n","\n","Key idea: randomly delete the connections between nodes to prevent overfitting.\n","\n","Source: https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf"]},{"cell_type":"markdown","metadata":{"id":"xj0aeJ_p3N_f"},"source":["#Mini-lab\n","\n","![adversarial attack](https://miro.medium.com/max/1400/1*n18mfvFgeZTLVxx07iBNkA.png)\n","\n","##Objective\n","This lab's objective is to show how neural network can be susceptible to transformed data. We also want to show how neural network can behave abnormally even though we can interpret the transformed data without any difficulty.\n","\n","Let's use the same model and digits data from yesterday\n","\n","Note: the model takes about 2 minutes to train"]},{"cell_type":"code","metadata":{"id":"wGAscLcoaWhy"},"source":["from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","from sklearn.neural_network import MLPClassifier # import multi-layer perceptron classifier\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","X_train = X_train.reshape(60000,784)\n","X_test = X_test.reshape(10000,784)\n","\n","hidden_layer_architecture = (764, 100)\n","\n","mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_architecture, max_iter=10, alpha=1e-4, \n","                     solver='sgd', verbose=10, tol=1e-4, random_state=1,\n","                     learning_rate_init=.1)\n","mlp.fit(X_train, y_train)\n","\n","print('\\ntraining score: {}'.format(mlp.score(X_train, y_train)))\n","print('test score: {}'.format(mlp.score(X_test, y_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r42SEIqjYw7P"},"source":["Let's see what the noisy data looks like to us. Try running the module below and change index!"]},{"cell_type":"code","metadata":{"id":"48kQwIBsahwT"},"source":["import numpy as np\n","import random\n","import cv2\n","\n","random.seed(1)\n","_, (X_test_2, y_test_2) = mnist.load_data()\n","\n","def sp_noise(image,prob = .01):\n","    '''\n","    Add salt and pepper noise to image\n","    prob: Probability of the noise\n","    '''\n","    output = np.zeros(image.shape,np.uint8)\n","    thres = 1 - prob \n","    for i in range(image.shape[0]):\n","        for j in range(image.shape[1]):\n","            rdn = random.random()\n","            if rdn < prob:\n","                output[i][j] = 0\n","            elif rdn > thres:\n","                output[i][j] = random.randrange(0, 255)\n","            else:\n","                output[i][j] = image[i][j]\n","    return output\n","\n","noise_index = 150 # <--- CHANGE ME. change this index to see different test data\n","\n","# transform image by adding noise and then scale to [0,1]\n","img = X_test_2[noise_index].reshape((28,28))\n","noise_img = sp_noise(img).reshape(784)\n","noise_img = noise_img / 255.0\n","\n","output_noise = mlp.predict([noise_img]) # make a prediction\n","print(\"Predict below picture as: {}\".format(output_noise[0]))\n","plt.imshow(noise_img.reshape((28,28)), cmap=plt.get_cmap('gray'))\n","# show the figure\n","plt.show()\n","\n","print(\"while the true label is: {}\".format(y_test_2[noise_index]))\n","plt.imshow(X_test_2[noise_index].reshape((28,28)), cmap=plt.get_cmap('gray'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYTGjm1hZGLc"},"source":["The below module try to add noise to every test data. Then make a prediction on that noisy data. We want to see which picture the model predicts incorrectly"]},{"cell_type":"code","metadata":{"id":"dMZKRr_Wa0Kh"},"source":["# check indices of wrong prediction of noisy image\n","\n","random.seed(1)\n","sum = []\n","noisy_wrong_pred_indices = []\n","for i in range(10000):\n","  img = X_test_2[i].reshape((28,28))\n","  noise_img = sp_noise(img).reshape(784)\n","  noise_img = noise_img / 255.0\n","  output_noise = mlp.predict([noise_img])\n","  if (output_noise[0] != y_test_2[i]):\n","    sum.append(0)\n","    noisy_wrong_pred_indices.append(i)\n","  else:\n","    sum.append(1)\n","\n","print(\"Accuracy for noisy images: {}\".format(np.mean(sum)))\n","\n","#indices of wrong prediction of clean image\n","random.seed(1)\n","sum2 = []\n","clean_wrong_pred_indices = []\n","\n","for i in range(10000):\n","  if (mlp.predict([X_test_2[i].reshape(784) / 255.0])[0] != y_test_2[i]):\n","    sum2.append(0)\n","    clean_wrong_pred_indices.append(i)\n","  else:\n","    sum2.append(1)\n","\n","print(\"Accuracy for clean images: {}\".format(np.mean(sum2)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JmjCfyiSmlWc"},"source":["HMMM... The accuracy for noisy images becomes slightly lowered. Let's see which one the adversarial attack works.\n","\n","###Note: the below portion does not work perfectly. You can look at it as a reference. Please refer to the last module for more consistently adversarial attack"]},{"cell_type":"code","metadata":{"id":"UilAkPQrfnaB"},"source":["# show pictures that the model predicts incorrectly\n","# note: the model includes some incorrect prediction from both indices. This may be due to how random seed works differently in each module\n","# for more consistent data, please refer to the very last module\n","difference = [item for item in noisy_wrong_pred_indices if item not in clean_wrong_pred_indices]\n","\n","random.seed(1)\n","for noise_index in difference[:30]:\n","  img = X_test_2[noise_index].reshape((28,28))\n","  noise_img = sp_noise(img).reshape(784)\n","  noise_img = noise_img / 255.0\n","\n","  output_noise = mlp.predict([noise_img])\n","\n","  if output_noise[0] != y_test_2[noise_index]:\n","    print(\"index: \" + str(noise_index))\n","    print(\"Predict below picture as: {} \\nwhile the true label is: {}\".format(output_noise[0], y_test_2[noise_index]))\n","    plt.imshow(noise_img.reshape((28,28)), cmap=plt.get_cmap('gray'))\n","    # show the figure\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xg2udT2J1sJo"},"source":["Note: due to random seed somehow change in every ipynb section, the wrong prediction indices may be different for each of you.\n","\n","Try these three indices: **684, 4861, 6572**"]},{"cell_type":"code","metadata":{"id":"hmzDnwWJkP-f"},"source":["random.seed(1)\n","\n","# check for true value\n","\n","\n","''' try these three indices: 684, 4861, 6572 '''\n","noise_index = 684 # <--- change this index to see different test data\n","\n","img = X_test_2[noise_index].reshape((28,28))\n","noise_img = sp_noise(img).reshape(784)\n","noise_img = noise_img / 255\n","\n","# show noisy image and its wrong prediction\n","output_noise = mlp.predict([noise_img])\n","print(\"Predict noisy picture below as: {} \\nwhile the true label is: {}\".format(output_noise[0], y_test_2[noise_index]))\n","plt.imshow(noise_img.reshape((28,28)), cmap=plt.get_cmap('gray'))\n","plt.show()\n","\n","# double check with clean data\n","img = X_test_2[noise_index].reshape(784) / 255\n","print(\"\\nPredict clean data as: {}\".format(mlp.predict([img])[0]))\n","print(\"Clean data:\")\n","plt.imshow(img.reshape((28,28)), cmap=plt.get_cmap('gray'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ed6RlMzZaKwg"},"source":["In ML, this is a research area called adversarial machine learning. We want to make the model becomes more robust. Different techniques are used, such as training the model with noisy data. But the whole topic is too deep and our goal for this lab is to let you have fun with this lab. Maybe you can try to train the model with noisy data and see how it performs!"]}]}